{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # !mamba install -y pandas\n",
    "import difflib\n",
    "import dragonmapper.hanzi\n",
    "from itertools import combinations\n",
    "import jieba # !mamba install -y jieba\n",
    "\n",
    "remove_tone_symbols = lambda char_in_ipa: char_in_ipa.rstrip('˥').rstrip('˧˥').rstrip('˧˩˧').rstrip('˥˩')\n",
    "\n",
    "def compare(english_word_ipa, subset_ipa):\n",
    "    ratio = difflib.SequenceMatcher(None, subset_ipa, english_word_ipa).ratio()\n",
    "    # Punish length difference.\n",
    "    len_diff = abs(len(subset_ipa)-len(english_word_ipa))\n",
    "    score = ratio*(1-len_diff)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235886 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the English dictionary. Creating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 62896/235886 [09:44<27:11, 106.04it/s]"
     ]
    }
   ],
   "source": [
    "# 导入英文单词\n",
    "ENGLISH_DICT_PATH = \"english.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(ENGLISH_DICT_PATH)\n",
    "except:\n",
    "    print('Failed to load the English dictionary. Creating...')\n",
    "    import eng_to_ipa as ipa # !pip install eng-to-ipa\n",
    "    from tqdm import tqdm    # !mamba install -y tqdm\n",
    "    def convert_to_ipa(word, pbar):\n",
    "        pbar.update()\n",
    "        return ipa.convert(word)\n",
    "    df = pd.read_table('/usr/share/dict/words', header=None)\n",
    "    df.columns = ['word']\n",
    "    with tqdm(df) as pbar:\n",
    "        df['ipa'] = df['word'].apply(convert_to_ipa, pbar=pbar)\n",
    "    # 单词筛选\n",
    "    df = df[~df['ipa'].str.endswith('*')]\n",
    "    df.drop_duplicates('word', inplace=True)\n",
    "    df.drop_duplicates('ipa', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"{len(df)} words remain.\")\n",
    "    df.to_csv(ENGLISH_DICT_PATH, index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = \"据说明天有雨\"\n",
    "chinese_in_ipa = dragonmapper.hanzi.to_ipa(chinese)\n",
    "chars_in_ipa = chinese_in_ipa.split(' ')\n",
    "chars_in_ipa = list(map(remove_tone_symbols, chars_in_ipa))\n",
    "\n",
    "words = []\n",
    "words_in_ipa = []\n",
    "for word, start, end in jieba.tokenize(chinese):\n",
    "    word_in_ipa = chars_in_ipa[start:end]\n",
    "    word_in_ipa = ''.join(word_in_ipa)\n",
    "    words_in_ipa.append(word_in_ipa)\n",
    "    words.append(word)\n",
    "print(' '.join(words))\n",
    "\n",
    "dfs = []\n",
    "# For each possible substring.\n",
    "for x, y in combinations(range(len(words) + 1), r = 2):\n",
    "    subset_ipa = words_in_ipa[x:y]\n",
    "    subset_ipa = ''.join(subset_ipa)\n",
    "    this_df = df.assign(\n",
    "        diff_sim = df['ipa'].apply(compare, subset_ipa=subset_ipa)\n",
    "    )\n",
    "    this_df.sort_values('diff_sim', ascending=False, inplace=True)\n",
    "    this_df = this_df.head(3)\n",
    "    # These columns have the same content across rows. Thus, it is better to add them after truncating the rows.\n",
    "    this_df = this_df.assign(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        subset_ipa=subset_ipa,\n",
    "        subset_chinese=''.join(words[x:y]),\n",
    "        result=''.join(words[:x])+this_df['word']+''.join(words[y:]),\n",
    "    )\n",
    "    dfs.append(this_df)\n",
    "res_df = pd.concat(dfs)\n",
    "res_df.sort_values('diff_sim', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
