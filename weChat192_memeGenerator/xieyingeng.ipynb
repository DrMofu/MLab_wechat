{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # !mamba install -y pandas\n",
    "import difflib\n",
    "import dragonmapper.hanzi\n",
    "from itertools import combinations\n",
    "import jieba # !mamba install -y jieba\n",
    "from tqdm import tqdm    # !mamba install -y tqdm\n",
    "\n",
    "remove_tone_symbols = lambda char_in_ipa: char_in_ipa.rstrip('˥').rstrip('˧˥').rstrip('˧˩˧').rstrip('˥˩')\n",
    "\n",
    "def compare(english_word_ipa, subset_ipa):\n",
    "    ratio = difflib.SequenceMatcher(None, subset_ipa, english_word_ipa).ratio()\n",
    "    # Punish length difference.\n",
    "    len_diff = abs(len(subset_ipa)-len(english_word_ipa))\n",
    "    score = ratio*(1-len_diff)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the English dictionary. Creating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [19:23<00:00, 107.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107973 words remain.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a's</td>\n",
       "      <td>eɪz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  ipa\n",
       "0    a    ə\n",
       "1  a's  eɪz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import English dictionary.\n",
    "ENGLISH_DICT_PATH = \"english.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(ENGLISH_DICT_PATH)\n",
    "except:\n",
    "    print('Failed to load the English dictionary. Creating...')\n",
    "    import eng_to_ipa as ipa # !pip install eng-to-ipa\n",
    "    def convert_to_ipa(word, pbar):\n",
    "        pbar.update()\n",
    "        try:\n",
    "            return ipa.convert(word)\n",
    "        except:\n",
    "            return ''\n",
    "    words = ipa.mode_type('json').keys()\n",
    "    df = pd.DataFrame({'word': words})\n",
    "    with tqdm(df) as pbar: # Takes about 20 min.\n",
    "        df['ipa'] = df['word'].apply(convert_to_ipa, pbar=pbar)\n",
    "    # Filter words.\n",
    "    df = df[~df['ipa'].str.endswith('*')]\n",
    "    df.drop_duplicates('ipa', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"{len(df)} words remain.\")\n",
    "    df.to_csv(ENGLISH_DICT_PATH, index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山重水复 疑无路\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ipa</th>\n",
       "      <th>diff_sim</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>subset_ipa</th>\n",
       "      <th>subset_chinese</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>clune</td>\n",
       "      <td>klun</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>iulu</td>\n",
       "      <td>疑无路</td>\n",
       "      <td>山重水复clune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35457</th>\n",
       "      <td>fluet</td>\n",
       "      <td>flut</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>iulu</td>\n",
       "      <td>疑无路</td>\n",
       "      <td>山重水复fluet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69364</th>\n",
       "      <td>ooley</td>\n",
       "      <td>ˈuli</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>iulu</td>\n",
       "      <td>疑无路</td>\n",
       "      <td>山重水复ooley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21345</th>\n",
       "      <td>counterweight</td>\n",
       "      <td>ˈkaʊntərˌweɪt</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfu</td>\n",
       "      <td>山重水复</td>\n",
       "      <td>counterweight疑无路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>biosafety</td>\n",
       "      <td>ˌbaɪoʊˈseɪfti</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfu</td>\n",
       "      <td>山重水复</td>\n",
       "      <td>biosafety疑无路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21529</th>\n",
       "      <td>cowperthwaite</td>\n",
       "      <td>ˈkaʊpərθˌweɪt</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfu</td>\n",
       "      <td>山重水复</td>\n",
       "      <td>cowperthwaite疑无路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62843</th>\n",
       "      <td>microwavable</td>\n",
       "      <td>ˌmaɪkroʊˈweɪvəbəl</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfuiulu</td>\n",
       "      <td>山重水复疑无路</td>\n",
       "      <td>microwavable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67569</th>\n",
       "      <td>nomenclatorial</td>\n",
       "      <td>ˌnoʊmɪnkləˈtɔriəl</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfuiulu</td>\n",
       "      <td>山重水复疑无路</td>\n",
       "      <td>nomenclatorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62840</th>\n",
       "      <td>microtubules</td>\n",
       "      <td>ˈmaɪˌkroʊˈtubjulz</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ʂanʈʂʊŋʂweɪfuiulu</td>\n",
       "      <td>山重水复疑无路</td>\n",
       "      <td>microtubules</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word                ipa  diff_sim  x  y         subset_ipa  \\\n",
       "18374           clune               klun  0.500000  1  2               iulu   \n",
       "35457           fluet               flut  0.500000  1  2               iulu   \n",
       "69364           ooley               ˈuli  0.500000  1  2               iulu   \n",
       "21345   counterweight      ˈkaʊntərˌweɪt  0.384615  0  1      ʂanʈʂʊŋʂweɪfu   \n",
       "9688        biosafety      ˌbaɪoʊˈseɪfti  0.384615  0  1      ʂanʈʂʊŋʂweɪfu   \n",
       "21529   cowperthwaite      ˈkaʊpərθˌweɪt  0.384615  0  1      ʂanʈʂʊŋʂweɪfu   \n",
       "62843    microwavable  ˌmaɪkroʊˈweɪvəbəl  0.352941  0  2  ʂanʈʂʊŋʂweɪfuiulu   \n",
       "67569  nomenclatorial  ˌnoʊmɪnkləˈtɔriəl  0.294118  0  2  ʂanʈʂʊŋʂweɪfuiulu   \n",
       "62840    microtubules  ˈmaɪˌkroʊˈtubjulz  0.294118  0  2  ʂanʈʂʊŋʂweɪfuiulu   \n",
       "\n",
       "      subset_chinese            result  \n",
       "18374            疑无路         山重水复clune  \n",
       "35457            疑无路         山重水复fluet  \n",
       "69364            疑无路         山重水复ooley  \n",
       "21345           山重水复  counterweight疑无路  \n",
       "9688            山重水复      biosafety疑无路  \n",
       "21529           山重水复  cowperthwaite疑无路  \n",
       "62843        山重水复疑无路      microwavable  \n",
       "67569        山重水复疑无路    nomenclatorial  \n",
       "62840        山重水复疑无路      microtubules  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese = \"山重水复疑无路\"\n",
    "chinese_in_ipa = dragonmapper.hanzi.to_ipa(chinese)\n",
    "chars_in_ipa = chinese_in_ipa.split(' ')\n",
    "chars_in_ipa = list(map(remove_tone_symbols, chars_in_ipa))\n",
    "\n",
    "words = []\n",
    "words_in_ipa = []\n",
    "for word, start, end in jieba.tokenize(chinese):\n",
    "    word_in_ipa = chars_in_ipa[start:end]\n",
    "    word_in_ipa = ''.join(word_in_ipa)\n",
    "    words_in_ipa.append(word_in_ipa)\n",
    "    words.append(word)\n",
    "print(' '.join(words))\n",
    "\n",
    "dfs = []\n",
    "# For each possible substring.\n",
    "for x, y in combinations(range(len(words) + 1), r = 2):\n",
    "    subset_ipa = words_in_ipa[x:y]\n",
    "    subset_ipa = ''.join(subset_ipa)\n",
    "    this_df = df.assign(\n",
    "        diff_sim = df['ipa'].apply(compare, subset_ipa=subset_ipa)\n",
    "    )\n",
    "    this_df.sort_values('diff_sim', ascending=False, inplace=True)\n",
    "    this_df = this_df.head(3)\n",
    "    # These columns have the same content across rows. Thus, it is better to add them after truncating the rows.\n",
    "    this_df = this_df.assign(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        subset_ipa=subset_ipa,\n",
    "        subset_chinese=''.join(words[x:y]),\n",
    "        result=''.join(words[:x])+this_df['word']+''.join(words[y:]),\n",
    "    )\n",
    "    dfs.append(this_df)\n",
    "res_df = pd.concat(dfs)\n",
    "res_df.sort_values('diff_sim', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
